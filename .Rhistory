ls
debug(lm)
debug(ls)
ls()
1
ï¼Ÿsolve
?solve
a <- matrix(1:16, 4, 4)
a
solve(a, 1)
t(a)
solve(a)
solve(c) %*% c
ginv(a)
solve(a)
library(MASS)
ginv(a)
solve(a, ginv(a))
solve(a)
1.3*250*12
15000/250
1300000*.05%
1300000*.0005
1000000/6000
set.seed(1)
rpois(5, 2)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
?qpois
?rpois
system.time()
tables()
require(data.table)
install.packages("data.table")
require(data.table)
tables()
theDT <- data.table(A=1:10,
B=letters[1:10],
C=LETTERS[1:10],
D=rep(c("One", "Two", "Three"), length.out=10))
theDT
class(theDT$B)
theDF <- data.frame(theDT)
class(theDF$B)
theDF
tables()
theDT
setkey(theDT, D)
theDT
diamonds
require(ggplot2)
data(diamonds)
diamondsDT <- data.table(diamonds)
aggregate(price ~ cut, diamonds, mean)
?aggregate
diamondsDT[, mean(price), by=cut]
?cbind
sport <- c(1, 2, 3)
sport
league <- 4:6
trophy <- 7:9
t1 <- cbind(sport, league, trophy)
t1
class(t1)
sport <- ("1", "2", "3")
sport <- c("1", "2", "3")
t1 <- cbind(sport, league, trophy)
class(t1)
t
t1
getwd()
download.file(url="http://jaredlander.com/data/us-foreign_aid.zip", destfile="data/ForeignAid/zip")
download.file(url="http://jaredlander.com/data/us-foreign_aid.zip", destfile="data/ForeignAid.zip")
download.file(url="http://jaredlander.com/data/us_foreign_aid.zip", destfile="data/ForeignAid.zip")
download.file(url="http://jaredlander.com/datasets/us_foreign_aid.zip", destfile="data/ForeignAid.zip")
download.file(url="http://jaredlander.com/data/US_Foreign_Aid.zip", destfile="data/ForeignAid.zip")
require(stringr)
theFiles <- dir("data/", pattern="\\.csv")
for (file in theFiles) {
nameToUse <- str_sub(string=file, start=12, end=18)
temp <- read.table(file=file.path("data", file), head=TRUE, sep=",", stringsAsFactors=FALSE)
assign(x=nameToUse, value=temp)
}
2/7
37.06+72.52+35.96+15.64+292.73+10.16+1.04
37.06+72.52+35.96+15.64+292.73+10.16+1.04+11.18+5.99
getwd()
setwd()
library(swirl)
install_from_swirl("Getting and Cleaning Data")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringASFactors = F)
mydf <- read.csv(path2csv, stringASFactors = FALSE)
mydf <- read.csv(path2csv, stringASFactors = FALSE)
mydf <- read.csv(path2csv, stringAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
cran
filter(cran, country == "IN", r_version <- "3.0.2")
filter(cran, country == "IN", r_version <= "3.0.2")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(size:ip_id)
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, decs(ip_id))
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
1186.96+631.04
myapp <- oauth_app("github",
key = "77db6a8d7979e0753d77",
secret = "b01d2fef1317ef4d781e9645380d3e5f132981fd")
library(httr)
myapp <- oauth_app("github",
key = "77db6a8d7979e0753d77",
secret = "b01d2fef1317ef4d781e9645380d3e5f132981fd")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(sqldf)
acs <- read.csv("~/Google Drive/Data Science/03. Getting and Cleaning Data/wk2/getdata-data-ss06pid.csv")
View(acs)
dim(acs)
sqldf("select * from acs where AGEP < 50")
sqldf("select pwgtp1 from acs where AGEP < 50")
head(sqldf("select pwgtp1 from acs where AGEP < 50"))
sqldf("select * from acs where AGEP < 50 and pwgtp1")
library(httr)
library(jsonlite)
myapp <- oauth_app("github",
key = "a0c6d6af44f0d6dd0ed8",
secret = "4d07b21f2add9ca7d2b70b896dec680663fa4b39")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp, cache=FALSE)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
raw <- content(req)
jsoned <- jsonlite::fromJSON(toJSON(raw))
jsoned[jsoned$name == "datasharing"]$created_at
jsoned[jsoned$name == "datasharing"]
jsoned
head(jsoned)
jsoned$name
jsoned$name == "datasharing"
jsoned[jsoned$name == "datasharing"]
jsoned$created_at
jsoned[jsoned$name == "datasharing"]$created_at
jsoned[, jsoned$name == "datasharing"]
jsoned[jsoned$name == "datasharing", ]$created_at
jsoned[jsoned$name == "datasharing", ]
acs$AGEP
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
sqldf("select unique AGEP from acs")
sqldf("select AGEP where unique from acs")
colnames(acs)
dim(acs)
library(XML)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html <- htmlTreeParse(url, useInternalNodes=T)
html
readLines?
.93*.19
.93*..05
.93*.05
20-1-1.4
365+31+31+28+31+30+12
swirl()
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
9*40*22
quit()
9*20
9*40*4
9*40*4*12
40/1200
getdata.data.GDP <- read.csv("~/Google Drive/Data Science/03. Getting and Cleaning Data/wk3/getdata-data-GDP.csv")
View(getdata.data.GDP)
GDP <- getdata.data.GDP[1:190, ]
dim(DDP)
dim(GDP)
usd <- GDP$US.dollars.
usd
mean(usd)
gsub(",", "", usd)
mean(as.numeric(gsub(",", "", usd)))
library(datasets)
data(cars)
with(cars, plot(speed, dist))
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/Project 1/household_power_consumption.txt", sep=";")
View(power)
head(power)
?read.csv
power[power$Date == "01/02/2007"]
power$Date == "01/02/2007"
sum(power$Date == "01/02/2007")
attach(power)
unique(Date)
power[power$Date == "1/2/2007"]
power[power$Date == "1/2/2007", ]
power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
swirl()
library(swirl)
swirl()
filter(power, Date == "1/2/2007" | Date = "2/2/2007")
filter(power, Date == "1/2/2007" | Date == "2/2/2007")
filter(power, Date == "1/2/2007" | Date == "2/2/2007")
a = filter(power, Date == "1/2/2007" | Date == "2/2/2007")
colnames(power)
a = filter(power, Date == "1/2/2007")
class(power)
sample <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
rm(power)
rm(a)
attach(sample)
unique(Date)
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/
Project 1/household_power_consumption.txt", sep=";")
strptime(Date)
?strptime
as.Date
as.Date?
?as.Date
class(Date)
hist(Global_active_power, col='red', main='Global Active Power',
xlab='Global Active Power (kilowatts)')
sub_power <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/Project 1/household_power_consumption.txt", sep=";")
sub_power <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
attach(sample)
rm(power)
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/Project 1/household_power_consumption.txt", sep=";")
sub_power <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
attach(sample)
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/Project 1/household_power_consumption.txt", sep=";")
sub_power <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
attach(sub_power)
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/Project 1/household_power_consumption.txt", sep=";")
sub_power <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/Project 1/household_power_consumption.txt", sep=";")
sub_power <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
attach(sub_power)
rm(power)
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/Project 1/household_power_consumption.txt", sep=";")
household_power_consumption <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/datascience04_project01/household_power_consumption.txt", sep=";")
View(household_power_consumption)
dev.off()
# Read in data and subset
power <- read.csv("~/Google Drive/Data Science/04. Exploratory Data Analysis/datascience04_project01/household_power_consumption.txt", sep=";")
sub_power <- power[power$Date == "1/2/2007" | power$Date == "2/2/2007", ]
attach(sub_power)
rm(power)
# open png device
png(filename="plot1.png", bg="transparent", width=480, height=480)
# do the plotting
hist(sub_power, col='red', main='Global Active Power',xlab='Global Active Power (kilowatts)')
# close the device
dev.off()
hist(sub_power, col='red', main='Global Active Power',xlab='Global Active Power (kilowatts)')
hist(sub_power, col='red', main='Global Active Power',xlab='Global Active Power (kilowatts)')
# open png device
png(filename="plot1.png", bg="transparent", width=480, height=480)
# do the plotting
hist(Global_active_power, col='red', main='Global Active Power',xlab='Global Active Power (kilowatts)')
# close the device
dev.off()
hist(Global_active_power, col='red', main='Global Active Power',xlab='Global Active Power (kilowatts)')
Global_active_power
?subset
require(ggplot2)
x = rnorm(100)
y = x + rnorm(100)
qplot(y, x)
qplot(x, y)
str(mpg)
qplot(displ, hwy, data = mpg, color = drv)
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))
qplot(displ, hwy, dat = mpg, facets = .~drv)
qplot(displ, hwy, dat = mpg, facets = .~ drv)
qplot(displ, hwy, data = mpg, facets = .~ drv)
x = 1:100
y = rnorm(100)
testdat <- data.frame(x = 1:100, y = rnorm(100))
testdat[50, 2] <- 100
g <- ggplot(testdat, aes = (x = x, y = y))
g <- ggplot(testdat, aes(x = x, y = y))
g + geom_line()
library(lattice)
library(datasets)
class(xyplot(Ozone ~ Wind, data = airquality))
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
trellis.par.set()
trellis.par.set?
trellis.par.set()?
xyplot?
?xyplot
?trellis.par.set
?print.trellis
?par
?splom
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
head(airquality)
qplot(Wind, Ozone, data = airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
class(airquality$Month)
data(airquality)
class(airquality$Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
?points
?panel.lmline
R.version.string
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
swirl()
swirl()
head(pollution)
dim(pollution)
summary(pollution$pm25)
ppm
quantile(ppm)
boxplot(ppm)
boxplot(ppm, col='blue')
abline(h=12)
hist(ppm, col="green")
rug(ppm)
higr
high
loe
low
high
hist(ppm, col="green", breaks=100)
rug(ppm)
hist(ppm, col="green")
abline(v=12, lwd=2)
abline(v=median(ppm), col="magenta", lwd=4)
names(pollutions)
names(pollution)
pollution$region
reg <- table(pollution$region)
reg
barplot(regm col='wheat', main="Number of Counties in Each Region")
barplot(reg, col='wheat', main="Number of Counties in Each Region")
boxplot(pm25~region,data=pollution, col="red")
par(mfrow=c(2, 1), mar=c(4, 4, 2, 1))
east <- subset(pollution, region=="east")
head(east)
hist(east$pm25, col='green')
west <- subset(pollution, region=='west')
hist(subset(pollution, region=='west')$pm25, col='green')
\
swirl()
setwd("~/Google Drive/Data Science/05. Reproducible Research/RepData_PeerAssessment1")
activity_data <- read.csv(unz("activity.zip", "activity.csv"))
total_per_day = aggregate(steps ~ date, activity_data, sum)
hist(total_per_day$steps, main = "Total number of steps taken each day", xlab = "Steps")
# Calculate and report the mean and median total number of steps taken per day
mean(total_per_day$steps)
median(total_per_day$steps)
?plt
?plot
View(total_per_day)
plot(activity_data$interval, mean(activity_data$steps), type="l")
no_na_data = na.omit(activity_data)
plot(no_na_data$interval, mean(no_na_data$steps), type="l")
plot(no_na_data$interval, type="l")
head(activity_data)
max(activity_data$interval)
step_data = aggregate(steps ~ interval, activity_data, mean)
plot(step_data, type="l")
step_data
max(activity_data$steps)
max(activity_data$steps, na.rm = T)
activity_data$steps
?plot
step_data
max(step_data$steps)
activity_data[activity_data$interval == 835, ]
activity_data[activity_data$date == "2012-10-01", ]
step_data
max(step_data)
max(step_data$steps)
step_data[which.max(step_data$steps), ]
step_data[which.max(step_data$steps), ]$interval
nrow(na.omit(activity_data))
nrow(!na.omit(activity_data))
sum(is.na(activity_data))
17568-15264
sum(is.na(activity_data$steps))
sum(is.na(activity_data$date))
sum(is.na(activity_data$interval))
step_data
head(activity_data)
activity_data$interval == 0
step_data
head(activity_data)
activity_data[1, ]
is.na(activity_data[1, ])
head(step_data)
?cbind
cbind(activity_data, step_data)
head(cbind(activity_data, step_data))
bind <- cbind(activity_data, step_data)
View(bind)
merge(activity_data, step_data)
dim(merge(activity_data, step_data))
288*5
2400/5
View(step_data)
step_data
head(step_data)
colnames(step_data) <- c("Inteval", "Average steps")
step_data
head(step_data)
head(step_data)
colnames(step_data) <- c("Inteval", "avgSteps")
bind
binded <- rbind(activity_data, step_data)
binded <- cbind(activity_data, step_data)
View(binded)
step_data = aggregate(steps ~ interval, activity_data, mean)
colnames(step_data)
colnames(step_data)[1]
colnames(step_data)[2]
colnames(step_data)[2] <- "avgSteps"
colnames(step_data)
step_data[which.max(step_data$avgSteps), ]$interval
binded <- cbind(activity_data, step_data)
View(binded)
if(is.na(binded)) {
binded[1] = binded[5]
}
is.nam(binded)
is.na(binded)
binded[1]
binded[, 1]
binded[1, 1]
head(binded)
View(binded)
is.na(banded)
is.na(binded)
sum(is.na(binded))
binded <- cbind(activity_data, step_data)
sum(is.na(binded))
if(is.na(binded)) {
binded[1] = binded[5]
}
sum(is.na(binded))
View(binded)
complete_data <- cbind(activity_data, step_data)
if(is.na(complete_data)) {
complete_data[1] = complete_data[5]
}
View(complete_data)
complete_data <- cbind(activity_data, step_data)
if(is.na(complete_data)) complete_data[1] = complete_data[5]
View(complete_data)
complete_data <- cbind(activity_data, step_data)
View(complete_data)
complete_data <- cbind(activity_data, step_data)
if(is.na(complete_data)) {complete_data$steps = complete_data$avgSteps}
View(complete_data)
complete_data <- complete_data[, 3]
complete_data <- cbind(activity_data, step_data)
if(is.na(complete_data)) {complete_data$steps = complete_data$avgSteps}
complete_data <- complete_data[, 1:3]
View(complete_data)
